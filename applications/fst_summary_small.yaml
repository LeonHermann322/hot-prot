program: applications/train.py
method: bayes
name: fst_summary_small
command:
  - ${env}
  - ${interpreter}
  - ${program}
  - ${args}
  - --nolog
  - --wandb
  - --early_stopping
metric:
  name: loss
  goal: minimize
parameters:
  learning_rate:
    min: 0.001
    max: 0.05
  model_hidden_layers:
    values: [1,2,3,4]
  model_first_hidden_units:
    values: [1024, 2048, 4096]
  model_dropoutrate:
    min: 0.0
    max: 0.3
  epochs:
    values: [10]
  optimizer:
    values: ["adam"]
  weight_regularizer:
    min: 0.0
    max: 0.005
  dataset:
    values: ["fst"]
  model:
    values: ["summarizer"]
  batch_size:
    values: [32]
  representation_key:
    values: ["esm_35M"]
  factorized_rank:
    values: [1,2,4]
  seq_length:
    values: [700]
  loss:
    values: ["scaled_mse", "weighted_mse", "mse"]
  esm_version:
    values: ["esm2_t12_35M_UR50D"]
  summarizer_mode:
    values: ["per_residue", "per_repr_position"]
  summarizer_type:
    values: ["average"]
